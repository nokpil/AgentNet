{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T06:24:13.127399Z",
     "start_time": "2020-08-21T06:24:13.112440Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.deterministic = True\n",
    "\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"D:/OneDrive/연구/ML/MyProject/AgentNet\") #PC\n",
    "#importlib.reload(ML)\n",
    "import src.DataStructure as DS\n",
    "from src.utils import *\n",
    "from src.system import *\n",
    "from src.model import *\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "torch.set_printoptions(precision = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen():\n",
    "    def __init__(self, system):\n",
    "        pass\n",
    "    \n",
    "    def run(self, file_name, total_size, batch_size, train_ratio):\n",
    "\n",
    "        train_image = []\n",
    "        train_label = []\n",
    "        test_image = []\n",
    "        test_label = []\n",
    "        \n",
    "        batch_num = int(total_size/batch_size)\n",
    "        train_size = int(batch_num * train_ratio)\n",
    "        test_size = int(batch_num*(1-train_ratio))\n",
    "        \n",
    "        for i in range(train_size):\n",
    "            data, answer = next(system)\n",
    "            train_image.append(data.astype(float))\n",
    "            train_label.append(answer)\n",
    "\n",
    "        train_output = {'Image':train_image, 'Label':train_label}\n",
    "        \n",
    "        for i in range(test_size):\n",
    "            data, answer = next(system)\n",
    "            test_image.append(data.astype(float))\n",
    "            test_label.append(answer)\n",
    "        \n",
    "        test_output = {'Image':test_image, 'Label':test_label}\n",
    "            \n",
    "        # Output pickle\n",
    "        with open(file_name + '_train.pkl', 'wb') as f:\n",
    "            pickle.dump(train_output, f)\n",
    "            \n",
    "        with open(file_name + '_test.pkl', 'wb') as f:\n",
    "            pickle.dump(test_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T06:24:13.222148Z",
     "start_time": "2020-08-21T06:24:13.215165Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "pp = {}\n",
    "system = Flock_LSTM()\n",
    "\n",
    "pp['ob_num'] = 'A'\n",
    "pp['time_interval'] = 30\n",
    "system.assign_pp(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_set(system, i):\n",
    "    full_set = set([])\n",
    "    for s in range(system.step_num+1):\n",
    "        full_set = set.union(full_set, system.time_list[int(i+(s*system.time_interval))]['ID'])\n",
    "    full_set = np.sort(np.array(list(full_set)))\n",
    "    return full_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_next(self):\n",
    "\n",
    "    while True:\n",
    "        i = self.order[self.count]\n",
    "        \n",
    "        if self.count % 10 == 0:\n",
    "            print(self.count)\n",
    "        self.count += 1   \n",
    "        full_set = set([])\n",
    "        for s in range(system.step_num+1):\n",
    "            full_set = set.union(full_set, self.time_list[int(i+(s*self.time_interval))]['ID'])\n",
    "        full_set = np.sort(np.array(list(full_set)))\n",
    "        \n",
    "        data_input = self.time_list[i][['x', 'y', 'z', 'vx', 'vy', 'vz', 'hdg', 'hdg_rate', 'V']].values\n",
    "        data_input = np.concatenate((data_input, np.ones((data_input.shape[0], 1))), axis=1)\n",
    "        data = np.zeros((self.max_agent, self.state_num))\n",
    "        data = np.concatenate((data, (-1)*np.ones((data.shape[0], 1))), axis=1)\n",
    "        data[idx2idx(full_set, np.sort(np.array(list(set(self.time_list[int(i)]['ID'])))))] = data_input    \n",
    "        \n",
    "        answer_list = []\n",
    "\n",
    "        previous_set = set([])\n",
    "        present_set = set(self.time_list[int(i)]['ID'])\n",
    "        for s in range(self.step_num):\n",
    "            mask_input_new = np.zeros(self.max_agent)\n",
    "            mask_input_next = np.zeros(self.max_agent)\n",
    "            next_set = set(self.time_list[int(i + (s+1) * self.time_interval)]['ID'])\n",
    "            \n",
    "            # A : agents which exists in next step AND new entry (ready for hidden state init)\n",
    "            new_set = present_set - previous_set\n",
    "            mask_input_new[idx2idx(full_set, np.sort(np.array(list(new_set))))] = 1 \n",
    "            \n",
    "            # B1 : agents in next step\n",
    "            mask_input_next[idx2idx(full_set, np.sort(np.array(list(next_set))))] = 1\n",
    "            \n",
    "            # B2 : agents which exists currently and next step (covers A)\n",
    "            present_next_set = set.intersection(present_set, next_set)\n",
    "            mask_input_next[idx2idx(full_set, np.sort(np.array(list(present_next_set))))] = 2 \n",
    "            \n",
    "            answer = np.zeros((self.max_agent, 2 + self.answer_num))\n",
    "            answer[:, 0] = mask_input_new\n",
    "            answer[:, 1] = mask_input_next\n",
    "\n",
    "            for x in self.time_list[int(i + (s+1) * self.time_interval)]['ID']:\n",
    "                idx_x = np.argwhere(full_set==x)[0][0]\n",
    "                answer[idx_x][2:] = (\n",
    "                self.time_list[int(i + (s+1) * self.time_interval)][self.time_list[int(i + (s+1) * self.time_interval)]['ID'] == x][\n",
    "                    ['x', 'y', 'z', 'vx', 'vy', 'vz', 'hdg', 'hdg_rate', 'V']]).values\n",
    "\n",
    "            answer_list.append(answer)\n",
    "            previous_set = present_set\n",
    "            present_set = next_set \n",
    "\n",
    "        return data, answer_list\n",
    "\n",
    "def max_agent_next(system):\n",
    "    max_agent = -1\n",
    "    for i in range(0 , system.max_time, system.jump_interval):\n",
    "        full_set = set([])\n",
    "        for s in range(system.step_num+1):\n",
    "            full_set = set.union(full_set, system.time_list[int(i+(s)*system.time_interval)]['ID'])\n",
    "        max_agent = np.max((max_agent, len(full_set)))\n",
    "    return max_agent\n",
    "\n",
    "def max_agent_list(system):\n",
    "    agent_list = []\n",
    "    for i in range(0 , system.max_time, system.jump_interval):\n",
    "        full_set = set([])\n",
    "        for s in range(system.step_num+1):\n",
    "            full_set = set.union(full_set, system.time_list[int(i+(s)*system.time_interval)]['ID'])\n",
    "        agent_list.append(len(full_set))\n",
    "    return agent_list\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data, labels = zip(*batch)\n",
    "    data, labels = torch.stack(data), torch.stack(labels)\n",
    "\n",
    "    # data max\n",
    "    \n",
    "    data_checksum = torch.max(torch.argmax((data[:,:,-1]>0).double(), dim = 1)+1)\n",
    "    seq_sum = torch.sum((labels[:,:,:,1]>1).float(), dim = 1)\n",
    "    label_checksum = torch.max(torch.argmax((torch.sum(labels[:,:,:,1], dim = 1)>0).double(), dim = 1)+1)\n",
    "    #print(data_checksum, label_checksum)\n",
    "    cm = torch.max(data_checksum, label_checksum)\n",
    "    seq_len = seq_sum[:, :cm] \n",
    "\n",
    "    data, labels = data[:,:cm,:], labels[:,:,:cm, :]\n",
    "\n",
    "    mask_input_new = labels[:,:,:,0].unsqueeze(-1)\n",
    "    mask_input_next = ((labels[:,:,:,1].unsqueeze(-1))>0).float()\n",
    "    mask_input_check = ((labels[:,:,:,1].unsqueeze(-1))>1).float()\n",
    "    labels = labels[:,:,:,2:]\n",
    "\n",
    "    present = torch.zeros_like(mask_input_next[:,0,:,0])\n",
    "    zero_present = torch.zeros_like(mask_input_next[:,0,:,0])\n",
    "    target_mask_list = [[] for _ in range(labels.shape[1])]\n",
    "\n",
    "    for i in range(labels.shape[1]):\n",
    "        present += (mask_input_check[:,i,:,0]>0).float()\n",
    "        for j in range(labels.shape[1]):\n",
    "            target_mask_list[i].append((present==(j+1)).float())\n",
    "        present = torch.where(present == seq_len, torch.zeros_like(zero_present), present)\n",
    "\n",
    "    return data, labels, target_mask_list, mask_input_new, mask_input_next, mask_input_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system loaded\n",
    "\n",
    "system.step_num = 10\n",
    "system.time_interval = 30\n",
    "system.jump_interval = 20\n",
    "system.max_time = len(system.time_list) - system.step_num * system.time_interval\n",
    "system.order = np.arange(0, system.max_time, system.jump_interval)\n",
    "system.count = 0\n",
    "agent_list = max_agent_list(system)\n",
    "system.max_agent = 1886 \n",
    "with open('./data/Flock/system/'+'flock_lstm_OBA_agent_list.pkl', 'wb') as f:\n",
    "    pickle.dump(agent_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size parameters\n",
    "single_data_size = 198\n",
    "total_data_size = single_data_size * 1\n",
    "batch_size = 1\n",
    "train_ratio = 0.8\n",
    "filename = ''\n",
    "\n",
    "batch_num = int(total_data_size/batch_size)\n",
    "train_size = int(batch_num * train_ratio)\n",
    "test_size = int(batch_num*(1-train_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating new dataset\n",
    "system.time_interval = 30\n",
    "file_name = system.rule_name + '_OB'+str('A') + '_TI' + str(system.time_interval) + '_JI' + str(system.jump_interval) + '_LSTM'\n",
    "generator = DataGen(system)\n",
    "if not os.path.isfile(file_name+'_train.pkl'):\n",
    "    generator.run(file_name, total_data_size, batch_size, train_ratio)\n",
    "#generator.run(file_name, total_data_size, batch_size, train_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}